{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import boolean\n",
    "import scipy.sparse as sparse\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building STG table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBNet(filename):\n",
    "    bnet_model = {}\n",
    "    algebra = boolean.BooleanAlgebra()\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            species, formula = [value.strip() for value in line.split(\",\")]\n",
    "            if species != \"target\" and formula != \"factors\":\n",
    "                b_formula = algebra.parse(formula).simplify()\n",
    "                bnet_model.update({species:b_formula})\n",
    "                \n",
    "    return bnet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, loading the model as a minibn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\n",
    "    'mammalian_cc', \n",
    "    'krasmodel15vars',\n",
    "    'breast_cancer_zanudo2017',\n",
    "    'EMT_cohen_ModNet',\n",
    "    'sahin_breast_cancer_refined',\n",
    "    'toy',\n",
    "    'toy2',\n",
    "    'toy3'\n",
    "]\n",
    "model_index = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = readBNet((\"model_files/%s.bnet\" % model_name_list[model_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(nodes)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then, actually building the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_gen_node_update(formula, list_binary_states, nodes):\n",
    "\n",
    "    if isinstance(formula, boolean.boolean.Symbol):\n",
    "        return list_binary_states[:, nodes.index(str(formula))]\n",
    "    \n",
    "    elif isinstance(formula, boolean.boolean.NOT):\n",
    "        return np.logical_not(\n",
    "            fcn_gen_node_update(formula.args[0], list_binary_states, nodes)\n",
    "        )\n",
    "    \n",
    "    elif isinstance(formula, boolean.boolean.OR):\n",
    "        ret = fcn_gen_node_update(formula.args[0], list_binary_states, nodes)\n",
    "        for i in range(1, len(formula.args)):\n",
    "            ret = np.logical_or(ret, \n",
    "                fcn_gen_node_update(formula.args[i], list_binary_states, nodes)\n",
    "            )\n",
    "        return ret\n",
    "    \n",
    "    elif isinstance(formula, boolean.boolean.AND):\n",
    "        ret = fcn_gen_node_update(formula.args[0], list_binary_states, nodes)\n",
    "        for i in range(1, len(formula.args)):\n",
    "            ret = np.logical_and(ret, \n",
    "                fcn_gen_node_update(formula.args[i], list_binary_states, nodes)\n",
    "            )\n",
    "        return ret\n",
    "    \n",
    "    else:\n",
    "        print(\"Unknown boolean operator : %s\" % type(formula))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_build_update_table(model, list_binary_states, nodes):\n",
    "    update_matrix = np.array(\n",
    "        [\n",
    "            fcn_gen_node_update(model[node], list_binary_states, nodes) \n",
    "            for node in nodes\n",
    "        ]\n",
    "    ).transpose()\n",
    "    \n",
    "    return update_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_states_inds(yes_no, n_series_exp, n_isl_exp):\n",
    "    \n",
    "    n_series_exp = n_series_exp - 1\n",
    "    yes_no = yes_no - 1\n",
    "    \n",
    "    f_mat = np.array(\n",
    "        range(\n",
    "            1, \n",
    "            pow(2, (n_series_exp-n_isl_exp))+1\n",
    "        )\n",
    "    ) + yes_no\n",
    "\n",
    "    t_repmat = np.array([f_mat]*int(pow(2, n_isl_exp)))\n",
    "        \n",
    "    t_reshaped = np.reshape(t_repmat, (1, int(pow(2, n_series_exp))), order='F')\n",
    "    \n",
    "    t_mult = t_reshaped*pow(2, n_isl_exp)\n",
    "    t_last = np.array(\n",
    "        range(\n",
    "            1, \n",
    "            pow(2, n_series_exp)+1\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return np.sum([t_last, t_mult])-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_build_stg_table(model, nodes):\n",
    "    list_binary_states = np.remainder(\n",
    "        np.floor(\n",
    "            np.multiply(\n",
    "                np.array([range(pow(2, n))]).transpose(), \n",
    "                np.array([np.power([2.0]*n, np.array(range(0, -n, -1)))])\n",
    "            )\n",
    "        ), 2\n",
    "    ).astype(bool)\n",
    "    \n",
    "    update_table = fcn_build_update_table(model, list_binary_states, nodes)\n",
    "    \n",
    "    up_trans_source = [\n",
    "        np.intersect1d(\n",
    "            np.nonzero(update_table[:, x])[0],\n",
    "            fcn_states_inds(0, n, x)[0, :]\n",
    "        ) \n",
    "        for x in range(n)\n",
    "    ]\n",
    "        \n",
    "    down_trans_source = [\n",
    "        np.intersect1d(\n",
    "            np.nonzero(np.logical_not(update_table[:, x]))[0],\n",
    "            fcn_states_inds(1, n, x)[0, :]\n",
    "        ) \n",
    "        for x in range(n)\n",
    "    ]\n",
    "    \n",
    "    down_trans_target = [\n",
    "        np.concatenate(\n",
    "            (\n",
    "                np.array([down_trans_source[x]-pow(2, x)]).transpose(), \n",
    "                np.repeat(np.array([[x,1]]), len(down_trans_source[x]), axis=0)\n",
    "            ), axis=1\n",
    "        )\n",
    "        for x in range(len(down_trans_source))\n",
    "    ]\n",
    "    \n",
    "    up_trans_target = [\n",
    "        np.concatenate(\n",
    "            (\n",
    "                np.array([up_trans_source[x]+pow(2, x)]).transpose(), \n",
    "                np.repeat(np.array([[x,0]]), len(up_trans_source[x]), axis=0)\n",
    "            ), axis=1\n",
    "        )\n",
    "        for x in range(len(up_trans_source))\n",
    "    ]\n",
    "    \n",
    "    source = np.concatenate([\n",
    "        np.concatenate(down_trans_source, axis=0),\n",
    "        np.concatenate(up_trans_source, axis=0)\n",
    "    ])\n",
    "\n",
    "    target = np.concatenate([\n",
    "        np.concatenate(down_trans_target, axis=0),\n",
    "        np.concatenate(up_trans_target, axis=0)\n",
    "    ])\n",
    "    \n",
    "    stg_table = np.concatenate((np.array([source]).transpose(), target), axis=1)\n",
    "    \n",
    "    return stg_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9961472, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stg_table = fcn_build_stg_table(model, nodes)\n",
    "stg_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304.00Mbytes\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2fMbytes\" % (stg_table.shape[0] * stg_table.shape[1] * stg_table.itemsize / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building transition rates table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define transition rates, we can select given rates to have different values than 1, or from randomly chosen\n",
    "# name of rates: 'u_nodename' or 'd_nodename'\n",
    "# chosen_rates=['u_ERBB1','u_ERBB2','u_ERBB3']; chosen_rates_vals=np.zeros(len(chosen_rates));\n",
    "# OR leave them empty: \n",
    "chosen_rates = []\n",
    "chosen_rates_vals = []\n",
    "\n",
    "# chosen_rates = [\"u_CHEK1\", \"d_CHEK1\"]\n",
    "# chosen_rates_vals = np.ones(len(chosen_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we generate the table of transition rates: first row is the 'up'rates, second row 'down' rates, \n",
    "# in the order of 'nodes'\n",
    "# ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_type = ['uniform', 'random'] # <uniform> assigns a value of 1 to all params. other option: <random>\n",
    "meanval = 0.5 # if 'random' is chosen, the mean and standard dev of a normal distrib has to be defined\n",
    "sd_val = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_trans_rates_table(nodes, uniform_or_rand, meanval, sd_val, chosen_rates, chosen_rates_vals):\n",
    "    n = len(nodes)\n",
    "\n",
    "    if uniform_or_rand == \"uniform\":\n",
    "        rate_vals_num = np.ones((1, 2*n)).astype(np.int64)\n",
    "\n",
    "    elif uniform_or_rand == \"random\":\n",
    "        rate_vals_num = np.random.normal(meanval, sd_val, (1, 2*n))\n",
    "        if np.any(rate_vals_num < 0):\n",
    "            neg_cnt = 0\n",
    "            while np.any(rate_vals_num < 0):\n",
    "                rate_vals_num = np.random.normal(meanval, sd_val, (1, 2*n))\n",
    "                neg_cnt += 1\n",
    "                if neg_cnt > 100:\n",
    "                    break\n",
    "                    \n",
    "    else:\n",
    "        print(\"Choose 'uniform' or 'random' to generate transition rates\", file=sys.stderr)\n",
    "        return\n",
    "\n",
    "    for k, chosen_rate in enumerate(chosen_rates):\n",
    "        split_rate = chosen_rate.split(\"_\")\n",
    "        if len(split_rate) > 2:\n",
    "            node_mod_ind = \"_\".join(split_rate[1:])\n",
    "        else:\n",
    "            node_mod_ind = split_rate[1]\n",
    "\n",
    "        if split_rate[0] == \"d\":\n",
    "            rate_vals_num[:, nodes.index(node_mod_ind)+n] = chosen_rates_vals[k]\n",
    "        elif split_rate[0] == \"u\":\n",
    "            rate_vals_num[:, nodes.index(node_mod_ind)] = chosen_rates_vals[k]\n",
    "        else:\n",
    "            print(\"Wrong name for transition rate, has to be 'u_nodename' or 'd_nodename'\", file=sys.stderr)\n",
    "            return\n",
    "    \n",
    "    return np.reshape(rate_vals_num, (n, 2)).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_rates_table = fcn_trans_rates_table(nodes, distr_type[0], meanval, sd_val, chosen_rates, chosen_rates_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the (sparse) transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_build_trans_matr(stg_table, transition_rates_table, kin_matr_flag=\"\"):\n",
    "\n",
    "    dim_matr = pow(2, transition_rates_table.shape[1])\n",
    "    \n",
    "    rate_inds = ((stg_table[:, 2])*2)+stg_table[:, 3]\n",
    "\n",
    "    # Here we reshape the transition_rates_table to a list\n",
    "    reshaped_trt = np.reshape(transition_rates_table, (1, np.product(transition_rates_table.shape)), order=\"F\")[0, :]\n",
    "\n",
    "    B = sparse.csr_matrix(\n",
    "        (\n",
    "            reshaped_trt[rate_inds]/np.sum(transition_rates_table),\n",
    "            (stg_table[:, 0], \n",
    "            stg_table[:, 1])\n",
    "        ),\n",
    "        shape=(dim_matr, dim_matr)\n",
    "    )\n",
    "\n",
    "    A_sparse = B + (sparse.eye(B.shape[0]) - sparse.diags(np.array(sparse.csr_matrix.sum(B, axis=1).transpose())[0]))\n",
    "\n",
    "    if len(kin_matr_flag) > 0:\n",
    "        K_sparse = (A_sparse.transpose() - sparse.eye(A_sparse.shape[0]))*np.sum(transition_rates_table)\n",
    "\n",
    "    else:\n",
    "        K_sparse = []\n",
    "\n",
    "    return A_sparse, K_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sparse, _ = fcn_build_trans_matr(stg_table, transition_rates_table, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.00 Mbytes\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f Mbytes\" % (A_sparse.data.nbytes/(1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_fixed_nodes_list = [\n",
    "    ['CycE','CycA','CycB','Cdh1','Rb_b1','Rb_b2','p27_b1','p27_b2'], # mammalian_cc\n",
    "    ['cc','KRAS','DSB','cell_death'], #krasmodel15vars\n",
    "    ['Alpelisib', 'Everolimus','PIM','Proliferation','Apoptosis'], # breast_cancer_zanudo2017\n",
    "    ['ECMicroenv','DNAdamage','Metastasis','Migration','Invasion','EMT','Apoptosis','Notch_pthw','p53'], # EMT_cohen_ModNet \n",
    "    ['EGF','ERBB1','ERBB2','ERBB3','p21','p27'], # sahin_breast_cancer_refined\n",
    "    ['A','C','D'], # toy model with fork in stg\n",
    "    ['A', 'B', 'C'], # toy model with cycle in stg\n",
    "    ['A', 'B'] # smaller toy model with cycle in stg, one connected component\n",
    "] \n",
    "\n",
    "initial_fixed_nodes_vals_list = [\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1], # mammalian_cc\n",
    "    [1, 1, 1, 0], # krasmodel15vars: [1 1] is cell cycle ON, KRAS mutation ON\n",
    "    [0, 1, 0] + [0]*2, # breast_cancer_zanudo2017\n",
    "    [1, 1] + [0]*5 + [1, 0], # EMT-Cohen model: [0/1 0/1 zeros(1,5)]\n",
    "    [1, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0],\n",
    "    [0, 0, 0],\n",
    "    [0, 0]\n",
    "] \n",
    "\n",
    "initial_fixed_nodes = initial_fixed_nodes_list[model_index]\n",
    "initial_fixed_nodes_vals = initial_fixed_nodes_vals_list[model_index]\n",
    "\n",
    "\n",
    "# what is the probability of this state, (eg. dom_prob=0.8, ie. 80% probability)\n",
    "dom_prob = 1\n",
    "# if plot_flag non-empty, we get a bar plot of initial values\n",
    "plot_flag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_define_initial_states(initial_fixed_nodes,initial_fixed_nodes_vals,dom_prob,nodes,distrib_type,plot_flag):\n",
    "    \n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    truth_table_inputs = np.remainder(\n",
    "        np.floor(\n",
    "            np.multiply(\n",
    "                np.array([range(pow(2, n_nodes))]).transpose(), \n",
    "                np.array([np.power([2.0]*n_nodes, np.array(range(0, -n_nodes, -1)))])\n",
    "            )\n",
    "        ), 2\n",
    "    ).astype(bool)\n",
    "    \n",
    "    # define initial values\n",
    "    x0 = np.zeros((int(pow(2, n_nodes)), 1))\n",
    "    \n",
    "    # defining a dominant initial state (eg. dom_prob=0.8, ie. 80% probability\n",
    "    initial_on_nodes_inds = [node in initial_fixed_nodes for node in nodes]                                  \n",
    "\n",
    "    statespace_decim = np.sum(\n",
    "        truth_table_inputs[:, initial_on_nodes_inds]*np.power(\n",
    "            2, \n",
    "            np.array(\n",
    "                list(reversed(range(np.sum(initial_on_nodes_inds))))\n",
    "            )\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    initial_fixed_nodes_vals_decim = np.sum(\n",
    "        initial_fixed_nodes_vals*np.power(\n",
    "            2, \n",
    "            np.array(\n",
    "                list(reversed(range(len(initial_fixed_nodes_vals))))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    inds_condition = np.isin(statespace_decim, initial_fixed_nodes_vals_decim)\n",
    "\n",
    "    if distrib_type == \"uniform\":\n",
    "        x0[inds_condition] = np.array([[dom_prob/sum(inds_condition)]*sum(inds_condition)]).transpose()\n",
    "        x0[np.logical_not(inds_condition)] = np.array([[(1-dom_prob)/(len(x0)-sum(inds_condition))]*(len(x0)-sum(inds_condition))]).transpose()\n",
    "    \n",
    "    elif distrib_type == \"random\":\n",
    "        x0[inds_condition] = np.random.uniform(0, 1, (sum(inds_condition), 1))\n",
    "        x0 = dom_prob*x0/sum(x0)\n",
    "\n",
    "        x0[np.logical_not(inds_condition)] = np.random.uniform(0, 1, (len(x0)-sum(inds_condition), 1))\n",
    "        x0[np.logical_not(inds_condition)] = (1-dom_prob)*x0[np.logical_not(inds_condition)]/sum(x0[np.logical_not(inds_condition)])\n",
    "    \n",
    "    else:\n",
    "        print(\"distrib type should be 'uniform' or 'random'\", file=sys.stderr)\n",
    "    \n",
    "    # rounding precision\n",
    "    n_prec=3;\n",
    "    if round(sum(x0)[0],n_prec) == 1:\n",
    "        print('sum(x0)=1, OK.')\n",
    "    \n",
    "    else:\n",
    "        print('sum(x0)~=1, something wrong!')\n",
    "\n",
    "#     if ~isempty(plot_flag)\n",
    "#     bar(x0); set(gca,'yscale','log'); xlim([1 2^n_nodes]); % ylim([(1-dom_prob)/2^n_nodes 1])\n",
    "#     % subplot(2,1,2); x0=fcn_define_initial_states(initial_on_nodes,dom_prob,nodes,'broad'); \n",
    "#     % bar(x0); xlim([1 2^13]);set(gca,'yscale','log'); ylim([(1-dom_prob)/2^n_nodes 1])\n",
    "#     end\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(x0)=1, OK.\n"
     ]
    }
   ],
   "source": [
    "x0 = fcn_define_initial_states(initial_fixed_nodes, initial_fixed_nodes_vals, dom_prob, nodes, \"uniform\", plot_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def fcn_metagraph_scc(A_sparse_sub):\n",
    "    \n",
    "    matr_size = A_sparse_sub.shape[0]\n",
    "\n",
    "    g_sub = nx.from_scipy_sparse_matrix(A_sparse_sub, create_using=nx.DiGraph())\n",
    "    g_sub.remove_edges_from(nx.selfloop_edges(g_sub))\n",
    "    \n",
    "    # Here we reverse it only for debugging purpose\n",
    "    # The order shouldn't matter, but it's nice to have the same as matlab\n",
    "    scc_list = list(reversed(list(nx.strongly_connected_components(g_sub))))\n",
    "    print(\"%d connected components\" % len(scc_list))\n",
    "\n",
    "    \n",
    "    num_verts_per_scc = []\n",
    "    scc_memb_per_vert = np.zeros((matr_size, 1))\n",
    "\n",
    "    for i, scc in enumerate(scc_list):\n",
    "        num_verts_per_scc.append(len(scc))\n",
    "        scc_memb_per_vert[list(scc),:] = i;\n",
    "        \n",
    "    # row, col = np.where((A_sparse_sub - np.diag(A_sparse_sub.diagonal())) > 0)\n",
    "    # Yet another trick to get the exact same results as matlab\n",
    "    # The difference is returning the list from parsing via columns or via rows, hopefully nothing critical\n",
    "    col, row = np.where((A_sparse_sub - np.diag(A_sparse_sub.diagonal())).transpose() > 0)\n",
    "\n",
    "    diff = scc_memb_per_vert[row] != scc_memb_per_vert[col]\n",
    "    \n",
    "    row_sel = row[np.where(diff[:, 0])]\n",
    "    col_sel = col[np.where(diff[:, 0])]\n",
    "\n",
    "    A_metagraph = sparse.csr_matrix(\n",
    "        (np.array(A_sparse_sub[row_sel, col_sel]).flatten(), \n",
    "        (scc_memb_per_vert[row_sel][:, 0], scc_memb_per_vert[col_sel][:, 0])),\n",
    "        shape=(len(num_verts_per_scc), len(num_verts_per_scc))\n",
    "    )\n",
    "\n",
    "    metagraph = nx.from_scipy_sparse_matrix(A_metagraph, create_using=nx.DiGraph())\n",
    "    metagraph_ordering=np.array(list(nx.topological_sort(metagraph)))\n",
    "    \n",
    "    terminal_scc_ind, _ = np.where(A_metagraph.sum(axis=1) == 0)\n",
    "    terminal_scc_pos = np.isin(metagraph_ordering, terminal_scc_ind)\n",
    "    \n",
    "    nonterm_scc_num = len(num_verts_per_scc) - len(terminal_scc_ind)\n",
    "\n",
    "    scc_sup1 = [i for i, scc in enumerate(scc_list) if len(scc) > 1]\n",
    "    \n",
    "    term_cycles_ind = set(scc_sup1).intersection(set(terminal_scc_ind))\n",
    "    where_terminal_scc_pos, = np.where(terminal_scc_pos)\n",
    "\n",
    "    if np.sum(np.logical_not(where_terminal_scc_pos>(nonterm_scc_num-1))) > 0:\n",
    "        nonterm_scc_inds = np.logical_not(np.isin(metagraph_ordering, terminal_scc_ind))\n",
    "        metagraph_ordering_terminal_bottom = np.concatenate([\n",
    "            metagraph_ordering[nonterm_scc_inds],\n",
    "            metagraph_ordering[terminal_scc_pos]\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        metagraph_ordering_terminal_bottom = metagraph_ordering\n",
    "\n",
    "\n",
    "    if len(term_cycles_ind) > 0:\n",
    "        \n",
    "        scc_cell_reordered = [scc_list[i] for i in metagraph_ordering_terminal_bottom]\n",
    "        # index of cells containing term cycles after reordering\n",
    "        term_cycles_ind, = np.where(np.isin(metagraph_ordering_terminal_bottom, np.array(list(term_cycles_ind))))\n",
    "\n",
    "        # we need a cell of the indices of certices withing whese\n",
    "        scc_cell_reordered_lengths = np.array([len(scc) for scc in scc_cell_reordered])\n",
    "        scc_cell_reordered_cumsum = np.cumsum(scc_cell_reordered_lengths)\n",
    "        \n",
    "        cycle_first_verts = scc_cell_reordered_cumsum[term_cycles_ind] - scc_cell_reordered_lengths[term_cycles_ind];\n",
    "        cycle_last_verts = scc_cell_reordered_cumsum[term_cycles_ind] - 1\n",
    "        \n",
    "        term_cycles_bounds = [np.concatenate([cycle_first_verts, cycle_last_verts])]\n",
    "        \n",
    "    else:\n",
    "        term_cycles_ind = []\n",
    "        term_cycles_bounds = []\n",
    "        \n",
    "\n",
    "    # reordered original vertices\n",
    "    vert_topol_sort = np.concatenate([list(scc_list[i]) for i in metagraph_ordering_terminal_bottom])\n",
    "    \n",
    "    return vert_topol_sort, term_cycles_ind, A_metagraph, scc_list, term_cycles_bounds\n",
    "\n",
    "\n",
    "def fcn_scc_subgraphs(A_sparse, x0):\n",
    "    \n",
    "    print(\"Indentifying SCCs\")\n",
    "    G = nx.from_scipy_sparse_matrix(A_sparse, create_using=nx.DiGraph())\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    # Here we get a generator. Do I really need to compute it now ?\n",
    "    subnetws = [list(g) for g in nx.weakly_connected_components(G)]\n",
    "    cell_subgraphs = []\n",
    "    scc_submats = []\n",
    "    nonempty_subgraphs = []\n",
    "#     print(len(subnetws))\n",
    "    print(\"Identifying SCCs in subgraphs\")\n",
    "    for i, subnet in enumerate(subnetws):\n",
    "        cell_subgraphs.append(subnet)\n",
    "        \n",
    "        # Slicing done it two steps : First the rows, which is the most efficient for csr sparse matrix\n",
    "        # then columns. I should probably dig deeper\n",
    "        t_sparse = A_sparse[subnet, :][:, subnet]\n",
    "        \n",
    "        t_g = nx.from_scipy_sparse_matrix(t_sparse, create_using=nx.DiGraph())\n",
    "        t_g.remove_edges_from(nx.selfloop_edges(t_g))\n",
    "        \n",
    "        # Again, do I really need to compute it ?\n",
    "        scc_submats.append([list(g) for g in nx.strongly_connected_components(t_g)])\n",
    "\n",
    "        if sum(x0[subnet]) > 0:\n",
    "            nonempty_subgraphs.append(i)\n",
    "    \n",
    "    sorted_vertices = []\n",
    "    cyclic_sorted_subgraphs = []\n",
    "    counter = 0\n",
    "    \n",
    "    for nonempty_subgraph in nonempty_subgraphs:\n",
    "        \n",
    "        A_sparse_sub = A_sparse[subnetws[nonempty_subgraph], :][:, subnetws[nonempty_subgraph]]\n",
    "    \n",
    "        if A_sparse_sub.shape[0] == len(scc_submats[nonempty_subgraph]):\n",
    "            t_g = nx.from_scipy_sparse_matrix(A_sparse_sub, create_using=nx.DiGraph())\n",
    "            t_g.remove_edges_from(nx.selfloop_edges(t_g))\n",
    "            sorted_vertices.append(list(nx.topological_sort(t_g)))\n",
    "#             print(\"toposort results\")\n",
    "#             print(list(nx.topological_sort(t_g)))\n",
    "        else:\n",
    "            print(\"Cycles in STG\")\n",
    "            \n",
    "            # If entire graph is only one connected component, no need for re-ordering\n",
    "            if len(scc_submats[nonempty_subgraph]) == 1:\n",
    "                sorted_vertices.append(scc_submats[nonempty_subgraph])\n",
    "            else:\n",
    "                vert_topol_sort,term_cycles_ind,_,scc_cell,term_cycle_bounds=fcn_metagraph_scc(A_sparse_sub)\n",
    "                cycle_lengths = [len(scc) for scc in scc_cell]\n",
    "                \n",
    "                a = np.zeros((max(cycle_lengths)))\n",
    "                for i in range(max(cycle_lengths)):\n",
    "                    for j in cycle_lengths:\n",
    "                        if j == i+1:\n",
    "                            a[j-1] += 1\n",
    "                    \n",
    "                print('Cycles of lenth: %s (%s times)' % (set(cycle_lengths), a[np.where(a>0)]) )\n",
    "                cyclic_sorted_subgraphs.append((vert_topol_sort, term_cycles_ind, term_cycle_bounds))\n",
    "\n",
    "        counter += 1\n",
    "               \n",
    "    return (subnetws,scc_submats,nonempty_subgraphs,sorted_vertices,cyclic_sorted_subgraphs)\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indentifying SCCs\n",
      "Identifying SCCs in subgraphs\n",
      "Cycles in STG\n",
      "512036 connected components\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.00 TiB for an array with shape (524288, 524288) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-945ddb2b3c73>\u001b[0m in \u001b[0;36mfcn_scc_subgraphs\u001b[0;34m(A_sparse, x0)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0msorted_vertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscc_submats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnonempty_subgraph\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                 \u001b[0mvert_topol_sort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm_cycles_ind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscc_cell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mterm_cycle_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcn_metagraph_scc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_sparse_sub\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m                 \u001b[0mcycle_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscc_cell\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-945ddb2b3c73>\u001b[0m in \u001b[0;36mfcn_metagraph_scc\u001b[0;34m(A_sparse_sub)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Yet another trick to get the exact same results as matlab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# The difference is returning the list from parsing via columns or via rows, hopefully nothing critical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_sparse_sub\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_sparse_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscc_memb_per_vert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mscc_memb_per_vert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/exastolog/lib/python3.7/site-packages/numpy/lib/twodim_base.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.00 TiB for an array with shape (524288, 524288) and data type float64"
     ]
    }
   ],
   "source": [
    "%time stg_sorting_cell = fcn_scc_subgraphs(A_sparse, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_block_inversion(K_sp_sub_reord, sorted_vertices_terminal_bottom, x0, submatrix_inds):\n",
    "    \"\"\"\n",
    "        This function calculate kernels and stationary solution if all terminal\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Construct kernels from matrix blocks\n",
    "    dim_kernel = sum(K_sp_sub_reord.diagonal() == 0)\n",
    "    dim_matr = K_sp_sub_reord.shape[0]\n",
    "    \n",
    "    colnum_r_null_array = range(dim_kernel)\n",
    "    term_block_inds = range(dim_matr - dim_kernel, dim_matr)\n",
    "    nonterm_block_inds = range(dim_matr - dim_kernel)\n",
    "    term_block = sparse.eye(dim_kernel)\n",
    "  \n",
    "    # Right kernel\n",
    "    r0_blocks = sparse.lil_matrix((dim_matr, dim_kernel), dtype=np.float32)\n",
    "    r0_blocks[np.ix_(term_block_inds, colnum_r_null_array)] = term_block    \n",
    "    \n",
    "    # Left kernel\n",
    "    l0_blocks = sparse.lil_matrix((r0_blocks.shape[0], r0_blocks.shape[1]), dtype=np.float32).transpose()\n",
    "    nonzeros = r0_blocks.nonzero()\n",
    "    l0_blocks[(nonzeros[1], nonzeros[0])] = 1\n",
    "    \n",
    "    X_block = (\n",
    "        -r0_blocks[np.ix_(term_block_inds, colnum_r_null_array)]\n",
    "        *K_sp_sub_reord[np.ix_(term_block_inds, nonterm_block_inds)]\n",
    "    )\n",
    "    \n",
    "    # Solution 6\n",
    "    # https://stackoverflow.com/questions/1007442/mrdivide-function-in-matlab-what-is-it-doing-and-how-can-i-do-it-in-python\n",
    "    #TL;DR: A/B = np.linalg.solve(B.conj().T, A.conj().T).conj().T\n",
    "    # import time\n",
    "    # import scipy\n",
    "    # Here we have 3 solutions : scipy sparse, scipy dense, numpy\n",
    "    # And numpy is faster on the kras example\n",
    "    # Using sparse solve\n",
    "    \n",
    "    # t0 = time.time()\n",
    "    # X_block = sparse.linalg.spsolve(\n",
    "    #     K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].tocsr().conj().transpose(),\n",
    "    #     X_block.conj().transpose()\n",
    "    # ).conj().transpose()\n",
    "    \n",
    "    # Using scipy solve\n",
    "    # t1 = time.time()\n",
    "    # X_block = scipy.linalg.solve(\n",
    "    #     K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].todense().conj().transpose(),\n",
    "    #     X_block.todense().conj().transpose()\n",
    "    # ).conj().transpose()\n",
    "    \n",
    "    # Using numpy's solve\n",
    "    # t2 = time.time()\n",
    "    X_block = np.linalg.solve(\n",
    "        K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].toarray().conj().transpose(),\n",
    "        X_block.toarray().conj().transpose()\n",
    "    ).conj().transpose()\n",
    "    # print(\"1 : %.2gs, 2 : %.2gs, 3 : %.2gs\" % (t1-t0, t2-t1, time.time()-t2))\n",
    "    \n",
    "    l0_blocks[np.ix_(colnum_r_null_array, nonterm_block_inds)] = X_block;\n",
    "\n",
    "    stat_sol_submatr_blocks = r0_blocks * l0_blocks * x0[submatrix_inds[sorted_vertices_terminal_bottom]]\n",
    "    \n",
    "    return stat_sol_submatr_blocks\n",
    "\n",
    "def fcn_adjug_matrix(A, col_arg):\n",
    "    \n",
    "    size_array = np.array(list(range(A.shape[0])))\n",
    "    size_vect = len(size_array)\n",
    "    adj_matrix = None\n",
    "    if A.shape[0] == A.shape[1]:\n",
    "\n",
    "        if len(col_arg) == 0:\n",
    "            print(\"NOT IMPLEMENTED\")\n",
    "\n",
    "            #if a is a double\n",
    "\n",
    "            #else if a is symbolic\n",
    "\n",
    "            #end\n",
    "\n",
    "            #for k in range(size_vect):\n",
    "            #    for l in range(size_vect):\n",
    "            #        adj_matrix = truc\n",
    "\n",
    "            #if a is symbolic, we simplify\n",
    "\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            import scipy\n",
    "            \n",
    "#             adj_matrix\n",
    "            adj_matrix = []\n",
    "            for k in size_array:\n",
    "                adj_matrix.append(\n",
    "                    pow(-1, k)*\n",
    "                    scipy.linalg.det(\n",
    "                        A[np.ix_(\n",
    "                            range(1,size_vect), \n",
    "                            size_array[np.where(size_array != k)[0]]\n",
    "                        )].todense()\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    else: #non square matrix\n",
    "        adj_matrix = []\n",
    "        print(\"non-square matrix\")\n",
    "        \n",
    "    \n",
    "    return adj_matrix\n",
    "\n",
    "def fcn_left_kernel(K_sp_sub_reord, r0_blocks, dim_matr):\n",
    "    \n",
    "    print(\"Constructing left kernel\")\n",
    "\n",
    "    if len(r0_blocks.shape) > 1:\n",
    "        dim_kernel = np.sum(np.logical_not(np.isin(np.sum(r0_blocks, axis=1), 0)))\n",
    "        colnum_r_null_array = range(r0_blocks.shape[1])\n",
    "        size_r0_blocks = r0_blocks.shape\n",
    "    else:\n",
    "        print(\"Here we have a problem, the r0_blocks is actually 1D. Trying... RESULTS NEED TO BE CHECKED !!!\")\n",
    "    \n",
    "#         dim_kernel = np.sum(np.logical_not(np.isin(r0_blocks, 0)))\n",
    "#         colnum_r_null_array = [0]\n",
    "#         size_r0_blocks = [r0_blocks.shape[0], 1]\n",
    "\n",
    "    term_block_inds = range(dim_matr -dim_kernel,dim_matr)\n",
    "    nonterm_block_inds = range(dim_matr-dim_kernel)\n",
    "    \n",
    "    l0_blocks = sparse.lil_matrix((size_r0_blocks[0], size_r0_blocks[1])).transpose()\n",
    "    t_inds = np.where(np.logical_not(np.isin(r0_blocks, 0)).transpose())\n",
    "    \n",
    "    l0_blocks[t_inds] = 1\n",
    "    \n",
    "    X_block = (\n",
    "        -l0_blocks[np.ix_(colnum_r_null_array,term_block_inds)]\n",
    "        *K_sp_sub_reord[np.ix_(term_block_inds, nonterm_block_inds)]\n",
    "    )\n",
    "    \n",
    "    # Using numpy's solve\n",
    "    X_block = np.linalg.solve(\n",
    "        K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].toarray().conj().transpose(),\n",
    "        X_block.toarray().conj().transpose()\n",
    "    ).conj().transpose()\n",
    "    \n",
    "    l0_blocks[np.ix_(colnum_r_null_array, nonterm_block_inds)] = X_block\n",
    "    \n",
    "    return l0_blocks\n",
    "\n",
    "def split_calc_inverse(A_sparse, stg_sorting_cell, transition_rates_table, x0):\n",
    "    (subnetws,scc_submats,nonempty_subgraphs,sorted_vertices,cyclic_sorted_subgraphs) = stg_sorting_cell\n",
    "    \n",
    "    # is the STG disconnected?\n",
    "    stat_sol_blocks=sparse.lil_matrix((x0.shape[0], 1))\n",
    "    # A_digraph=digraph(A_sparse,'omitselfloops'); \n",
    "    num_subnets = len(subnetws)\n",
    "    # preallocate cell of term vertices and of subgraphs\n",
    "    term_verts = []\n",
    "    cell_subgraphs = []\n",
    "\n",
    "    if num_subnets>1:\n",
    "        print('STG has multiple subgraphs')\n",
    "\n",
    "    counter_subgraphs=0\n",
    "    \n",
    "    for i in nonempty_subgraphs:\n",
    "        \n",
    "        submatrix_inds = np.array(subnetws[i])\n",
    "        cell_subgraphs.append(submatrix_inds)\n",
    "\n",
    "        if num_subnets > 1:\n",
    "            print(\"Calculating subgraph #%d of %d\" % (i+1, num_subnets))\n",
    "            \n",
    "        A_sparse_sub = A_sparse[subnetws[i], :][:, subnetws[i]]\n",
    "        dim_matr = A_sparse_sub.shape[0]\n",
    "        scc_submat = scc_submats[i]\n",
    "        \n",
    "        # IF all SCCs are single vertices (ie. no cycles)\n",
    "        if len(set([tuple(t_submat) for t_submat in scc_submat])) == dim_matr:\n",
    "            \n",
    "            # function to reorder vertices and keep ordering\n",
    "            terminal_nodes = np.where(A_sparse_sub.diagonal() == 1)\n",
    "#             print(terminal_nodes)\n",
    "            # this is a consistent ordering but terminals are not necessarily in lower right corner of matrix\n",
    "            A_orig_reordered = A_sparse_sub[sorted_vertices[counter_subgraphs], :][:, sorted_vertices[counter_subgraphs]]\n",
    "\n",
    "            \n",
    "            # but we want to have terminal states acolnum_r_null_arrayt the bottom\n",
    "            #print(sorted_vertices[counter_subgraphs])\n",
    "            # This weird assignment syntax is because it returns a tuple of length one. This is valid, and it works\n",
    "            terminal_indices, = np.where(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes))\n",
    "            terminal_rem_inds, = np.where(np.logical_not(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes)))\n",
    "            t_inds, = np.where(np.logical_not(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes)))\n",
    "            \n",
    "            array_sorted_vertices = np.array(sorted_vertices[counter_subgraphs])\n",
    "\n",
    "            sorted_vertices_terminal_bottom = (\n",
    "                list(array_sorted_vertices[t_inds]) + list(array_sorted_vertices[terminal_indices])\n",
    "#                 axis=1\n",
    "            )\n",
    "                  \n",
    "            reordered_terminal_inds = list(terminal_rem_inds) + list(terminal_indices)\n",
    "            \n",
    "            A_sparse_sub_reordered_terminal = A_orig_reordered[reordered_terminal_inds, :][:, reordered_terminal_inds]\n",
    "            \n",
    "            K_sp_sub_reord = (A_sparse_sub_reordered_terminal.transpose() - sparse.eye(dim_matr)) * sum(transition_rates_table.flatten())\n",
    "\n",
    "            stat_sol_submatr_blocks = fcn_block_inversion(K_sp_sub_reord, sorted_vertices_terminal_bottom, x0, submatrix_inds)\n",
    "\n",
    "            stat_sol_blocks[submatrix_inds[sorted_vertices_terminal_bottom]] = stat_sol_submatr_blocks\n",
    "            term_verts.append(set(stat_sol_blocks.nonzero()[0]).intersection(set(submatrix_inds)))\n",
    "            \n",
    "        else:\n",
    "           \n",
    "            print('cycles in STG')\n",
    "            if len(scc_submat) == 1:\n",
    "#             % if entire graph is one connected component, no reordering needed\n",
    "                K_sp_sub_reord = (A_sparse_sub.transpose() - sparse.eye(dim_matr, dim_matr)) * sum(transition_rates_table.flatten())\n",
    "                kernel_col = np.dot(pow(-1, (dim_matr-1)), fcn_adjug_matrix(K_sp_sub_reord, 'col'))\n",
    "                # normalization\n",
    "                r0_blocks = (kernel_col.transpose()/np.sum(kernel_col))\n",
    "                if len(r0_blocks.shape) == 1:\n",
    "                    r0_blocks = r0_blocks.reshape(r0_blocks.shape[0], 1)\n",
    "                    \n",
    "                l0_blocks = fcn_left_kernel(K_sp_sub_reord, r0_blocks, dim_matr)\n",
    "                \n",
    "                #stat sol\n",
    "                stat_sol_submatr_blocks = np.dot(r0_blocks*l0_blocks,x0[submatrix_inds])\n",
    "                \n",
    "                stat_sol_blocks[submatrix_inds] = stat_sol_submatr_blocks\n",
    "                term_verts.append(submatrix_inds)\n",
    "                \n",
    "                \n",
    "\n",
    "            else:\n",
    "                print(\"Not a unique connected component\")\n",
    "            \n",
    "                vert_topol_sort = cyclic_sorted_subgraphs[counter_subgraphs][0]\n",
    "                term_cycles_ind = cyclic_sorted_subgraphs[counter_subgraphs][1]\n",
    "                term_cycle_bounds = cyclic_sorted_subgraphs[counter_subgraphs][2]\n",
    "            \n",
    "                A_sparse_sub_reordered_terminal = A_sparse_sub[vert_topol_sort,:][:, vert_topol_sort]\n",
    "                K_sp_sub_reord = (A_sparse_sub_reordered_terminal.transpose() - sparse.eye(dim_matr, dim_matr))*sum(transition_rates_table.flatten())\n",
    "\n",
    "\n",
    "                # if cycles are non-terminal, stat sol can be calculated by block inversion, sames as for acyclic graphs\n",
    "                if len(term_cycles_ind) == 0:\n",
    "                    print(\"Empty term cycles ind\")\n",
    "                    print(\" NEEDS TO BE TESTED\")\n",
    "#                      % here make sure if 'vert_topol_sort' is the right ordering...\n",
    "                    stat_sol_submatr_blocks = fcn_block_inversion(K_sp_sub_reord, vert_topol_sort, x0, submatrix_inds)\n",
    "                    stat_sol_blocks[submatrix_inds[vert_topol_sort]] = stat_sol_submatr_blocks\n",
    "                    term_verts_cell.append(submatrix_inds[vert_topol_sort[np.where(K_sp_sub_reord.diagonal() == 0)]])\n",
    "\n",
    "                else:\n",
    "                    print(\"Non empty term cycles ind\")\n",
    "                    \n",
    "                    # if there are terminal cycles, stat sol calc a bit more complicated\n",
    "                    # need to identify terminal cycles, for corresponding columns of\n",
    "                    # kernel we'll need to calculate adjugate matrix\n",
    "\n",
    "                    # probably we don't want it in symbolic form, but just in case\n",
    "                    if K_sp_sub_reord.dtype == np.float64:\n",
    "                        r_null_cycles = sparse.lil_matrix((dim_matr, len(term_cycle_bounds)))\n",
    "                    \n",
    "                    else:\n",
    "                        print(\"NOT IMPLEMENTED\")\n",
    "                        return\n",
    "\n",
    "                    for k, term_cycle_bound in enumerate(term_cycle_bounds):\n",
    "                        cycle_inds = range(term_cycle_bound[0], term_cycle_bound[-1]+1)\n",
    "                 \n",
    "                        #calc kernel of scc\n",
    "                        scc_cycle = K_sp_sub_reord[cycle_inds, :][:, cycle_inds]\n",
    "                        # adjugate_matrix -> kernel\n",
    "                        n = len(cycle_inds)\n",
    "                        \n",
    "                        kernel_col = np.dot(pow(-1, n-1) , fcn_adjug_matrix(scc_cycle, 'col'))\n",
    "                        \n",
    "                        r_null_cycles[cycle_inds,k] = kernel_col/sum(kernel_col)\n",
    "                        \n",
    "                    # if there are single-vertex terminal states too\n",
    "                    if np.sum(np.isin(K_sp_sub_reord.diagonal(), 0)) > 0:\n",
    "                        \n",
    "                        print(\"single vertex terminal states\")\n",
    "                        print(\" NOT IMPLEMENTED\")\n",
    "#                          n_terminal=find(ismember(diag(K_sp_sub_reord),0))'; \n",
    "#                         r_null_single_vert = sparse(dim_matr,numel(n_terminal)); \n",
    "#                         % (1:numel(n_terminal)-1)*2 + n_terminal\n",
    "#                         r_null_single_vert( sub2ind(size(r_null_single_vert), n_terminal, 1:numel(n_terminal)) )=1;\n",
    "#                         % does the order of columns in the kernel matter? I think not, if l0_blocks consistent w r0_blocks\n",
    "#                         r0_blocks=[r_null_cycles r_null_single_vert];\n",
    "                        return\n",
    "                    else:\n",
    "                        print(\"no single vertex terminal states\")\n",
    "                        r0_blocks = r_null_cycles\n",
    "                        \n",
    "                    # calculate kernel\n",
    "                    l0_blocks = fcn_left_kernel(K_sp_sub_reord, r0_blocks, dim_matr)\n",
    "                    \n",
    "                    # stat sol\n",
    "                    stat_sol_submatr_blocks = r0_blocks*l0_blocks*x0[submatrix_inds[vert_topol_sort]]\n",
    "                    stat_sol_blocks[submatrix_inds[vert_topol_sort]] = stat_sol_submatr_blocks\n",
    "                    row, col = r0_blocks.nonzero()\n",
    "                    \n",
    "                    pre_term_verts = []\n",
    "                    \n",
    "                    for k in range(len(set(col))):\n",
    "                        pre_term_verts.append(\n",
    "                            submatrix_inds[vert_topol_sort[row[np.where(col == k)]]]\n",
    "                        )\n",
    "                    term_verts.append(pre_term_verts)\n",
    "\n",
    "        counter_subgraphs +=1\n",
    "    return stat_sol_blocks, term_verts, cell_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stg_sorting_cell' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stg_sorting_cell' is not defined"
     ]
    }
   ],
   "source": [
    "%time stat_sol,term_verts_cell,cell_subgraphs=split_calc_inverse(A_sparse,stg_sorting_cell,transition_rates_table,x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stat_sol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-83d846df7841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_sol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stat_sol' is not defined"
     ]
    }
   ],
   "source": [
    "print(stat_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_sol.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
