{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import boolean\n",
    "import scipy.sparse as sparse\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building STG table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readBNet(filename):\n",
    "    bnet_model = {}\n",
    "    algebra = boolean.BooleanAlgebra()\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            species, formula = [value.strip() for value in line.split(\",\")]\n",
    "            if species != \"target\" and formula != \"factors\":\n",
    "                b_formula = algebra.parse(formula).simplify()\n",
    "                bnet_model.update({species:b_formula})\n",
    "                \n",
    "    return bnet_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, loading the model as a minibn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\n",
    "    'mammalian_cc', \n",
    "    'krasmodel15vars',\n",
    "    'breast_cancer_zanudo2017',\n",
    "    'EMT_cohen_ModNet',\n",
    "    'sahin_breast_cancer_refined',\n",
    "    'toy'\n",
    "]\n",
    "model_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = readBNet((\"model_files/%s.bnet\" % model_name_list[model_index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(model.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=len(nodes)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Then, actually building the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188416, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exastolog.StateTransitionTable import StateTransitionTable\n",
    "stg_table = StateTransitionTable(model, nodes).stg_table\n",
    "stg_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.75Mbytes\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2fMbytes\" % (stg_table.shape[0] * stg_table.shape[1] * stg_table.itemsize / (1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building transition rates table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to define transition rates, we can select given rates to have different values than 1, or from randomly chosen\n",
    "# name of rates: 'u_nodename' or 'd_nodename'\n",
    "# chosen_rates=['u_ERBB1','u_ERBB2','u_ERBB3']; chosen_rates_vals=np.zeros(len(chosen_rates));\n",
    "# OR leave them empty: \n",
    "chosen_rates = []\n",
    "chosen_rates_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we generate the table of transition rates: first row is the 'up'rates, second row 'down' rates, \n",
    "# in the order of 'nodes'\n",
    "# ARGUMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "distr_type = ['uniform', 'random'] # <uniform> assigns a value of 1 to all params. other option: <random>\n",
    "meanval = 0.5 # if 'random' is chosen, the mean and standard dev of a normal distrib has to be defined\n",
    "sd_val = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 15)\n",
      "(2, 15)\n"
     ]
    }
   ],
   "source": [
    "from exastolog.TransRateTable import TransRateTable\n",
    "transition_rates_table = TransRateTable(nodes, distr_type[0], meanval, sd_val, chosen_rates, chosen_rates_vals).table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building the (sparse) transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_build_trans_matr(stg_table, transition_rates_table, kin_matr_flag=\"\"):\n",
    "\n",
    "    dim_matr = pow(2, transition_rates_table.shape[1])\n",
    "    \n",
    "    rate_inds = ((stg_table[:, 2])*2)+stg_table[:, 3]\n",
    "\n",
    "    # Here we reshape the transition_rates_table to a list\n",
    "    reshaped_trt = np.reshape(transition_rates_table, (1, np.product(transition_rates_table.shape)), order=\"F\")[0, :]\n",
    "\n",
    "    B = sparse.csr_matrix(\n",
    "        (\n",
    "            reshaped_trt[rate_inds]/np.sum(transition_rates_table),\n",
    "            (stg_table[:, 0], \n",
    "            stg_table[:, 1])\n",
    "        ),\n",
    "        shape=(dim_matr, dim_matr)\n",
    "    )\n",
    "\n",
    "    A_sparse = B + (sparse.eye(B.shape[0]) - sparse.diags(np.array(sparse.csr_matrix.sum(B, axis=1).transpose())[0]))\n",
    "\n",
    "    if len(kin_matr_flag) > 0:\n",
    "        K_sparse = (A_sparse.transpose() - sparse.eye(A_sparse.shape[0]))*np.sum(transition_rates_table)\n",
    "\n",
    "    else:\n",
    "        K_sparse = []\n",
    "\n",
    "    return A_sparse, K_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_sparse, _ = fcn_build_trans_matr(stg_table, transition_rates_table, 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.69 Mbytes\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f Mbytes\" % (A_sparse.data.nbytes/(1024*1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up initial values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_fixed_nodes_list = [\n",
    "    ['CycE','CycA','CycB','Cdh1','Rb_b1','Rb_b2','p27_b1','p27_b2'], # mammalian_cc\n",
    "    ['cc','KRAS','DSB','cell_death'], #krasmodel15vars\n",
    "    ['Alpelisib', 'Everolimus','PIM','Proliferation','Apoptosis'], # breast_cancer_zanudo2017\n",
    "    ['ECMicroenv','DNAdamage','Metastasis','Migration','Invasion','EMT','Apoptosis','Notch_pthw','p53'], # EMT_cohen_ModNet \n",
    "    ['EGF','ERBB1','ERBB2','ERBB3','p21','p27'], # sahin_breast_cancer_refined\n",
    "    ['A','C','D'] # toy model\n",
    "] \n",
    "\n",
    "initial_fixed_nodes_vals_list = [\n",
    "    [0, 0, 0, 1, 1, 1, 1, 1], # mammalian_cc\n",
    "    [1, 1, 1, 0], # krasmodel15vars: [1 1] is cell cycle ON, KRAS mutation ON\n",
    "    [0, 1, 0] + [0]*2, # breast_cancer_zanudo2017\n",
    "    [1, 1] + [0]*5 + [1, 0], # EMT-Cohen model: [0/1 0/1 zeros(1,5)]\n",
    "    [1, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0]\n",
    "] \n",
    "\n",
    "initial_fixed_nodes = initial_fixed_nodes_list[model_index]\n",
    "initial_fixed_nodes_vals = initial_fixed_nodes_vals_list[model_index]\n",
    "\n",
    "\n",
    "# what is the probability of this state, (eg. dom_prob=0.8, ie. 80% probability)\n",
    "dom_prob = 1\n",
    "# if plot_flag non-empty, we get a bar plot of initial values\n",
    "plot_flag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_define_initial_states(initial_fixed_nodes,initial_fixed_nodes_vals,dom_prob,nodes,distrib_type,plot_flag):\n",
    "    \n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    truth_table_inputs = np.remainder(\n",
    "        np.floor(\n",
    "            np.multiply(\n",
    "                np.array([range(pow(2, n_nodes))]).transpose(), \n",
    "                np.array([np.power([2.0]*n_nodes, np.array(range(0, -n_nodes, -1)))])\n",
    "            )\n",
    "        ), 2\n",
    "    ).astype(bool)\n",
    "    \n",
    "    # define initial values\n",
    "    x0 = np.zeros((int(pow(2, n_nodes)), 1))\n",
    "    \n",
    "    # defining a dominant initial state (eg. dom_prob=0.8, ie. 80% probability\n",
    "    initial_on_nodes_inds = [node in initial_fixed_nodes for node in nodes]                                  \n",
    "\n",
    "    statespace_decim = np.sum(\n",
    "        truth_table_inputs[:, initial_on_nodes_inds]*np.power(\n",
    "            2, \n",
    "            np.array(\n",
    "                list(reversed(range(np.sum(initial_on_nodes_inds))))\n",
    "            )\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    initial_fixed_nodes_vals_decim = np.sum(\n",
    "        initial_fixed_nodes_vals*np.power(\n",
    "            2, \n",
    "            np.array(\n",
    "                list(reversed(range(len(initial_fixed_nodes_vals))))\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    inds_condition = np.isin(statespace_decim, initial_fixed_nodes_vals_decim)\n",
    "\n",
    "    if distrib_type == \"uniform\":\n",
    "        x0[inds_condition] = np.array([[dom_prob/sum(inds_condition)]*sum(inds_condition)]).transpose()\n",
    "        x0[np.logical_not(inds_condition)] = np.array([[(1-dom_prob)/(len(x0)-sum(inds_condition))]*(len(x0)-sum(inds_condition))]).transpose()\n",
    "    \n",
    "    elif distrib_type == \"random\":\n",
    "        x0[inds_condition] = np.random.uniform(0, 1, (sum(inds_condition), 1))\n",
    "        x0 = dom_prob*x0/sum(x0)\n",
    "\n",
    "        x0[np.logical_not(inds_condition)] = np.random.uniform(0, 1, (len(x0)-sum(inds_condition), 1))\n",
    "        x0[np.logical_not(inds_condition)] = (1-dom_prob)*x0[np.logical_not(inds_condition)]/sum(x0[np.logical_not(inds_condition)])\n",
    "    \n",
    "    else:\n",
    "        print(\"distrib type should be 'uniform' or 'random'\", file=sys.stderr)\n",
    "    \n",
    "    # rounding precision\n",
    "    n_prec=3;\n",
    "    if round(sum(x0)[0],n_prec) == 1:\n",
    "        print('sum(x0)=1, OK.')\n",
    "    \n",
    "    else:\n",
    "        print('sum(x0)~=1, something wrong!')\n",
    "\n",
    "#     if ~isempty(plot_flag)\n",
    "#     bar(x0); set(gca,'yscale','log'); xlim([1 2^n_nodes]); % ylim([(1-dom_prob)/2^n_nodes 1])\n",
    "#     % subplot(2,1,2); x0=fcn_define_initial_states(initial_on_nodes,dom_prob,nodes,'broad'); \n",
    "#     % bar(x0); xlim([1 2^13]);set(gca,'yscale','log'); ylim([(1-dom_prob)/2^n_nodes 1])\n",
    "#     end\n",
    "\n",
    "    return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(x0)=1, OK.\n"
     ]
    }
   ],
   "source": [
    "x0 = fcn_define_initial_states(initial_fixed_nodes, initial_fixed_nodes_vals, dom_prob, nodes, \"uniform\", plot_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def fcn_metagraph_scc(A_sparse_sub):\n",
    "    \n",
    "    matr_size = A_sparse_sub.shape[0]\n",
    "    g_sub = nx.from_scipy_sparse_matrix(A_sparse_sub, create_using=nx.DiGraph())\n",
    "    g_sub.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return None, None, None, None, None\n",
    "\n",
    "\n",
    "def fcn_scc_subgraphs(A_sparse, x0):\n",
    "    \n",
    "    print(\"Indentifying SCCs\")\n",
    "    G = nx.from_scipy_sparse_matrix(A_sparse, create_using=nx.DiGraph())\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    # Here we get a generator. Do I really need to compute it now ?\n",
    "    subnetws = [list(g) for g in nx.weakly_connected_components(G)]\n",
    "    cell_subgraphs = []\n",
    "    scc_submats = []\n",
    "    nonempty_subgraphs = []\n",
    "#     print(len(subnetws))\n",
    "    print(\"Identifying SCCs in subgraphs\")\n",
    "    for i, subnet in enumerate(subnetws):\n",
    "        cell_subgraphs.append(subnet)\n",
    "        \n",
    "        # Slicing done it two steps : First the rows, which is the most efficient for csr sparse matrix\n",
    "        # then columns. I should probably dig deeper\n",
    "        t_sparse = A_sparse[subnet, :]\n",
    "        t_sparse = t_sparse[:, subnet]\n",
    "        \n",
    "        t_g = nx.from_scipy_sparse_matrix(t_sparse, create_using=nx.DiGraph())\n",
    "        t_g.remove_edges_from(nx.selfloop_edges(t_g))\n",
    "        \n",
    "        # Again, do I really need to compute it ?\n",
    "        scc_submats.append([list(g) for g in nx.strongly_connected_components(t_g)])\n",
    "\n",
    "        print(len(scc_submats[i]))\n",
    "        if sum(x0[subnet]) > 0:\n",
    "            nonempty_subgraphs.append(i)\n",
    "    \n",
    "    sorted_vertices = []\n",
    "    cyclic_sorted_subgraphs = []\n",
    "    counter = 0\n",
    "    for nonempty_subgraph in nonempty_subgraphs:\n",
    "        A_sparse_sub = A_sparse[subnetws[nonempty_subgraph], :]\n",
    "        A_sparse_sub = A_sparse_sub[:, subnetws[nonempty_subgraph]]\n",
    "    \n",
    "        if A_sparse_sub.shape[0] == len(scc_submats[nonempty_subgraph]):\n",
    "            t_g = nx.from_scipy_sparse_matrix(A_sparse_sub, create_using=nx.DiGraph())\n",
    "            t_g.remove_edges_from(nx.selfloop_edges(t_g))\n",
    "            sorted_vertices.append(list(nx.topological_sort(t_g)))\n",
    "#             print(\"toposort results\")\n",
    "#             print(list(nx.topological_sort(t_g)))\n",
    "        else:\n",
    "            print(\"Cycles in STG\")\n",
    "            \n",
    "            # If entire graph is only one connected component, no need for re-ordering\n",
    "            if len(scc_submats[nonempty_subgraph]) == 1:\n",
    "                sorted_vertices.append(scc_submats[nonempty_subgraph])\n",
    "            else:\n",
    "                print(\"NOT IMPLEMENTED YET\")\n",
    "                ## THIS IS NOT IMPLEMENTED YET, FOCUSING ON FINISHING THE FIRST EXAMPLE\n",
    "                vert_topol_sort,term_cycles_ind,_,scc_cell,term_cycle_bounds=fcn_metagraph_scc(A_sparse_sub)\n",
    "\n",
    "        counter += 1\n",
    "               \n",
    "    return (subnetws,scc_submats,nonempty_subgraphs,sorted_vertices,cyclic_sorted_subgraphs)\n",
    "                   \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indentifying SCCs\n",
      "Identifying SCCs in subgraphs\n",
      "8192\n",
      "8192\n",
      "8192\n",
      "8192\n",
      "CPU times: user 6.15 s, sys: 68.8 ms, total: 6.22 s\n",
      "Wall time: 6.21 s\n"
     ]
    }
   ],
   "source": [
    "%time stg_sorting_cell = fcn_scc_subgraphs(A_sparse, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_block_inversion(K_sp_sub_reord, sorted_vertices_terminal_bottom, x0, submatrix_inds):\n",
    "    \"\"\"\n",
    "        This function calculate kernels and stationary solution if all terminal\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Construct kernels from matrix blocks\n",
    "    dim_kernel = sum(K_sp_sub_reord.diagonal() == 0)\n",
    "    dim_matr = K_sp_sub_reord.shape[0]\n",
    "    \n",
    "    colnum_r_null_array = range(dim_kernel)\n",
    "    term_block_inds = range(dim_matr - dim_kernel, dim_matr)\n",
    "    nonterm_block_inds = range(dim_matr - dim_kernel)\n",
    "    term_block = sparse.eye(dim_kernel)\n",
    "  \n",
    "    # Right kernel\n",
    "    r0_blocks = sparse.lil_matrix((dim_matr, dim_kernel), dtype=np.float32)\n",
    "    r0_blocks[np.ix_(term_block_inds, colnum_r_null_array)] = term_block    \n",
    "    \n",
    "    # Left kernel\n",
    "    l0_blocks = sparse.lil_matrix((r0_blocks.shape[0], r0_blocks.shape[1]), dtype=np.float32).transpose()\n",
    "    nonzeros = r0_blocks.nonzero()\n",
    "    l0_blocks[(nonzeros[1], nonzeros[0])] = 1\n",
    "    \n",
    "    X_block = (\n",
    "        -r0_blocks[np.ix_(term_block_inds, colnum_r_null_array)]\n",
    "        *K_sp_sub_reord[np.ix_(term_block_inds, nonterm_block_inds)]\n",
    "    )\n",
    "    \n",
    "    # Solution 6\n",
    "    # https://stackoverflow.com/questions/1007442/mrdivide-function-in-matlab-what-is-it-doing-and-how-can-i-do-it-in-python\n",
    "    #TL;DR: A/B = np.linalg.solve(B.conj().T, A.conj().T).conj().T\n",
    "    # import time\n",
    "    # import scipy\n",
    "    # Here we have 3 solutions : scipy sparse, scipy dense, numpy\n",
    "    # And numpy is faster on the kras example\n",
    "    # Using sparse solve\n",
    "    \n",
    "    # t0 = time.time()\n",
    "    # X_block = sparse.linalg.spsolve(\n",
    "    #     K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].tocsr().conj().transpose(),\n",
    "    #     X_block.conj().transpose()\n",
    "    # ).conj().transpose()\n",
    "    \n",
    "    # Using scipy solve\n",
    "    # t1 = time.time()\n",
    "    # X_block = scipy.linalg.solve(\n",
    "    #     K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].todense().conj().transpose(),\n",
    "    #     X_block.todense().conj().transpose()\n",
    "    # ).conj().transpose()\n",
    "    \n",
    "    # Using numpy's solve\n",
    "    # t2 = time.time()\n",
    "    X_block = np.linalg.solve(\n",
    "        K_sp_sub_reord[np.ix_(nonterm_block_inds,nonterm_block_inds)].toarray().conj().transpose(),\n",
    "        X_block.toarray().conj().transpose()\n",
    "    ).conj().transpose()\n",
    "    # print(\"1 : %.2gs, 2 : %.2gs, 3 : %.2gs\" % (t1-t0, t2-t1, time.time()-t2))\n",
    "    \n",
    "    l0_blocks[np.ix_(colnum_r_null_array, nonterm_block_inds)] = X_block;\n",
    "\n",
    "    stat_sol_submatr_blocks = r0_blocks * l0_blocks * x0[submatrix_inds[sorted_vertices_terminal_bottom]]\n",
    "    \n",
    "    return stat_sol_submatr_blocks\n",
    "\n",
    "\n",
    "\n",
    "def split_calc_inverse(A_sparse, stg_sorting_cell, transition_rates_table, x0):\n",
    "    (subnetws,scc_submats,nonempty_subgraphs,sorted_vertices,cyclic_sorted_subgraphs) = stg_sorting_cell\n",
    "    \n",
    "    # is the STG disconnected?\n",
    "    stat_sol_blocks=sparse.lil_matrix((x0.shape[0], 1))\n",
    "    # A_digraph=digraph(A_sparse,'omitselfloops'); \n",
    "    num_subnets = len(subnetws)\n",
    "    # preallocate cell of term vertices and of subgraphs\n",
    "    term_verts = []\n",
    "    cell_subgraphs = []\n",
    "\n",
    "    if num_subnets>1:\n",
    "        print('STG has multiple subgraphs')\n",
    "\n",
    "    counter_subgraphs=0\n",
    "    \n",
    "    for i in nonempty_subgraphs:\n",
    "        \n",
    "        submatrix_inds = np.array(subnetws[i])\n",
    "        cell_subgraphs.append(submatrix_inds)\n",
    "\n",
    "        if num_subnets > 1:\n",
    "            print(\"Calculating subgraph #%d of %d\" % (i+1, num_subnets))\n",
    "            \n",
    "        A_sparse_sub = A_sparse[subnetws[i], :][:, subnetws[i]]\n",
    "        dim_matr = A_sparse_sub.shape[0]\n",
    "        scc_submat = scc_submats[i]\n",
    "        \n",
    "        # IF all SCCs are single vertices (ie. no cycles)\n",
    "        if len(set([tuple(t_submat) for t_submat in scc_submat])) == dim_matr:\n",
    "            \n",
    "            # function to reorder vertices and keep ordering\n",
    "            terminal_nodes = np.where(A_sparse_sub.diagonal() == 1)\n",
    "#             print(terminal_nodes)\n",
    "            # this is a consistent ordering but terminals are not necessarily in lower right corner of matrix\n",
    "            A_orig_reordered = A_sparse_sub[sorted_vertices[counter_subgraphs], :][:, sorted_vertices[counter_subgraphs]]\n",
    "\n",
    "            \n",
    "            # but we want to have terminal states at the bottom\n",
    "            #print(sorted_vertices[counter_subgraphs])\n",
    "            # This weird assignment syntax is because it returns a tuple of length one. This is valid, and it works\n",
    "            terminal_indices, = np.where(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes))\n",
    "            terminal_rem_inds, = np.where(np.logical_not(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes)))\n",
    "            t_inds, = np.where(np.logical_not(np.isin(sorted_vertices[counter_subgraphs], terminal_nodes)))\n",
    "            \n",
    "            array_sorted_vertices = np.array(sorted_vertices[counter_subgraphs])\n",
    "\n",
    "            sorted_vertices_terminal_bottom = (\n",
    "                list(array_sorted_vertices[t_inds]) + list(array_sorted_vertices[terminal_indices])\n",
    "#                 axis=1\n",
    "            )\n",
    "                  \n",
    "            reordered_terminal_inds = list(terminal_rem_inds) + list(terminal_indices)\n",
    "            \n",
    "            A_sparse_sub_reordered_terminal = A_orig_reordered[reordered_terminal_inds, :][:, reordered_terminal_inds]\n",
    "            \n",
    "            K_sp_sub_reord = (A_sparse_sub_reordered_terminal.transpose() - sparse.eye(dim_matr)) * sum(transition_rates_table.flatten())\n",
    "\n",
    "            stat_sol_submatr_blocks = fcn_block_inversion(K_sp_sub_reord, sorted_vertices_terminal_bottom, x0, submatrix_inds)\n",
    "\n",
    "            stat_sol_blocks[submatrix_inds[sorted_vertices_terminal_bottom]] = stat_sol_submatr_blocks\n",
    "            term_verts.append(set(stat_sol_blocks.nonzero()[0]).intersection(set(submatrix_inds)))\n",
    "            \n",
    "        else:\n",
    "            #Non implemented yet\n",
    "            print(\"Not implemented yet !\")\n",
    "            pass\n",
    "        \n",
    "        counter_subgraphs +=1\n",
    "    return stat_sol_blocks, term_verts, cell_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STG has multiple subgraphs\n",
      "Calculating subgraph #4 of 4\n",
      "CPU times: user 14.5 s, sys: 545 ms, total: 15 s\n",
      "Wall time: 3.96 s\n"
     ]
    }
   ],
   "source": [
    "%time stat_sol,term_verts_cell,cell_subgraphs=split_calc_inverse(A_sparse,stg_sorting_cell,transition_rates_table,x0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (35, 0)\t0.16982301660209487\n",
      "  (67, 0)\t0.01069429074391337\n",
      "  (291, 0)\t0.25817666968396225\n",
      "  (323, 0)\t0.01918748778666668\n",
      "  (16159, 0)\t0.3131778050428693\n",
      "  (16387, 0)\t0.09025865387229715\n",
      "  (16643, 0)\t0.1386820789120975\n"
     ]
    }
   ],
   "source": [
    "print(stat_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000002643901"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_sol.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
